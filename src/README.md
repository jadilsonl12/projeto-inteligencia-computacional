# Documenta√ß√£o do C√≥digo - sentiment_classifier.py

Este documento explica detalhadamente cada fun√ß√£o e classe do c√≥digo de classifica√ß√£o de sentimentos.

---

## üìã √çndice

1. [Classe SentimentClassifier](#classe-sentimentclassifier)
2. [M√©todos da Classe](#m√©todos-da-classe)
3. [Fun√ß√£o generate_visualizations](#fun√ß√£o-generate_visualizations)
4. [Fun√ß√£o main](#fun√ß√£o-main)

---

## Classe SentimentClassifier

Classe principal respons√°vel por todo o pipeline de classifica√ß√£o de sentimentos em avalia√ß√µes de filmes do IMDb.

### `__init__(self, model_type='logistic_regression', max_features=5000)`

**Descri√ß√£o:** Construtor da classe que inicializa o classificador de sentimentos.

**Par√¢metros:**
- `model_type` (str): Tipo de modelo a ser usado. Op√ß√µes:
  - `'logistic_regression'` - Regress√£o Log√≠stica (padr√£o, recomendado)
  - `'naive_bayes'` - Naive Bayes Multinomial
- `max_features` (int): N√∫mero m√°ximo de palavras/features que o TF-IDF vai considerar (padr√£o: 5000)

**O que faz:**
1. Armazena o tipo de modelo escolhido
2. Define o n√∫mero m√°ximo de features
3. Inicializa os atributos `vectorizer` e `model` como `None`
4. Cria uma inst√¢ncia do `WordNetLemmatizer` do NLTK para lematiza√ß√£o
5. Chama `_download_nltk_resources()` para garantir que os recursos do NLTK estejam dispon√≠veis

**Exemplo de uso:**
```python
# Criar classificador padr√£o (Regress√£o Log√≠stica, 5000 features)
classifier = SentimentClassifier()

# Criar com Naive Bayes e 10000 features
classifier = SentimentClassifier(model_type='naive_bayes', max_features=10000)
```

---

### `_get_project_dirs()` (m√©todo est√°tico)

**Descri√ß√£o:** Retorna os caminhos absolutos dos diret√≥rios principais do projeto.

**Par√¢metros:** Nenhum (m√©todo est√°tico)

**Retorna:** Dictionary com os caminhos:
- `'models'` - Pasta onde modelos treinados s√£o salvos
- `'data'` - Pasta onde dados processados s√£o salvos
- `'visualizations'` - Pasta onde gr√°ficos s√£o salvos

**O que faz:**
1. Usa `Path(__file__)` para obter o caminho do arquivo atual
2. Navega para o diret√≥rio pai (raiz do projeto)
3. Constr√≥i caminhos para as tr√™s pastas principais
4. Retorna um dicion√°rio com os caminhos

**Exemplo de uso:**
```python
dirs = SentimentClassifier._get_project_dirs()
print(dirs['models'])  # D:\projeto-inteligencia-computacional\models
```

---

### `_download_nltk_resources(self)`

**Descri√ß√£o:** Garante que todos os recursos necess√°rios do NLTK estejam baixados e dispon√≠veis.

**Par√¢metros:** Nenhum

**Retorna:** Nenhum

**O que faz:**
1. Define uma lista de recursos NLTK necess√°rios:
   - `punkt` - Tokenizador de senten√ßas
   - `punkt_tab` - Tabelas do tokenizador (NLTK 3.9+)
   - `stopwords` - Lista de palavras comuns (a, the, is, etc.)
   - `wordnet` - Base de dados lexical para lematiza√ß√£o
   - `omw-1.4` - Open Multilingual Wordnet
2. Para cada recurso, tenta encontr√°-lo no sistema
3. Se n√£o encontrar, faz o download automaticamente
4. Mostra mensagem no console quando est√° baixando

**Por que √© importante:** Sem esses recursos, o pr√©-processamento de texto falharia.

---

### `preprocess_text(self, text)`

**Descri√ß√£o:** Realiza todo o pr√©-processamento de texto necess√°rio para an√°lise de sentimentos.

**Par√¢metros:**
- `text` (str): Texto bruto a ser processado (review do filme)

**Retorna:** String com o texto limpo e processado

**O que faz (passo a passo):**

1. **Decodificar entidades HTML:**
   ```python
   text = unescape(text)  # &amp; ‚Üí &, &lt; ‚Üí <
   ```

2. **Remover tags HTML:**
   ```python
   text = re.sub(r'<.*?>', '', text)  # <br>, <p>, etc.
   ```

3. **Converter para min√∫sculas:**
   ```python
   text = text.lower()  # "GREAT Movie" ‚Üí "great movie"
   ```

4. **Remover URLs:**
   ```python
   text = re.sub(r'http\S+|www\S+', '', text)
   ```

5. **Remover caracteres especiais e n√∫meros:**
   ```python
   text = re.sub(r'[^a-z\s]', '', text)  # Mant√©m apenas letras e espa√ßos
   ```

6. **Tokeniza√ß√£o (dividir em palavras):**
   ```python
   tokens = word_tokenize(text)  # "great movie" ‚Üí ["great", "movie"]
   ```

7. **Remover stopwords (palavras comuns):**
   ```python
   # Remove: a, the, is, was, etc.
   # Remove palavras com menos de 3 caracteres
   tokens = [word for word in tokens if word not in stop_words and len(word) > 2]
   ```

8. **Lematiza√ß√£o (reduzir √† forma base):**
   ```python
   tokens = [self.lemmatizer.lemmatize(word) for word in tokens]
   # "movies" ‚Üí "movie", "running" ‚Üí "run"
   ```

9. **Juntar tokens em texto:**
   ```python
   return ' '.join(tokens)
   ```

**Exemplo:**
```python
# Entrada
text = "This movie was AMAZING! Best film I've seen in years!! üòç"

# Sa√≠da ap√≥s processamento
"movie amazing best film seen year"
```

---

### `load_data(self, sample_size=None, save_processed=True)`

**Descri√ß√£o:** Carrega o dataset IMDb, pr√©-processa os textos e opcionalmente salva em CSV.

**Par√¢metros:**
- `sample_size` (int, opcional): 
  - Se `None`: usa todo o dataset (50.000 exemplos)
  - Se n√∫mero: usa amostra aleat√≥ria (ex: 5000)
- `save_processed` (bool): Se `True`, salva dados processados em `/data/`

**Retorna:** Tupla com 4 elementos:
```python
(X_train, y_train, X_test, y_test)
# X_train: textos de treino processados
# y_train: labels de treino (0=negativo, 1=positivo)
# X_test: textos de teste processados
# y_test: labels de teste
```

**O que faz:**

1. **Carrega dataset da Hugging Face:**
   ```python
   dataset = load_dataset('imdb')  # 25k treino + 25k teste
   ```

2. **Converte para DataFrame do pandas:**
   - Facilita manipula√ß√£o dos dados
   - Permite uso de m√©todos como `.sample()` e `.apply()`

3. **Aplica amostragem (se solicitado):**
   ```python
   train_df = train_df.sample(n=sample_size, random_state=42)
   # random_state=42 garante reprodutibilidade
   ```

4. **Pr√©-processa todos os textos:**
   ```python
   train_df['processed_text'] = train_df['text'].apply(self.preprocess_text)
   # Aplica preprocess_text() em cada review
   ```

5. **Salva dados processados (se solicitado):**
   - Chama `_save_processed_data()` que cria 3 arquivos CSV

6. **Retorna dados prontos para treinamento**

**Por que usar sample_size?**
- Dataset completo demora ~10-15 minutos
- Amostra de 5000 exemplos: ~1-2 minutos
- √ötil para testes r√°pidos e desenvolvimento

---

### `_save_processed_data(self, train_df, test_df)`

**Descri√ß√£o:** Salva os dados pr√©-processados e estat√≠sticas em arquivos CSV na pasta `/data/`.

**Par√¢metros:**
- `train_df` (DataFrame): DataFrame com dados de treino
- `test_df` (DataFrame): DataFrame com dados de teste

**Retorna:** Nenhum

**O que faz:**

1. **Obt√©m diret√≥rio de dados:**
   ```python
   data_dir = self._get_project_dirs()['data']
   data_dir.mkdir(exist_ok=True)  # Cria pasta se n√£o existir
   ```

2. **Salva dados processados em CSV:**
   ```python
   # processed_train.csv - textos limpos + labels de treino
   # processed_test.csv - textos limpos + labels de teste
   ```

3. **Calcula estat√≠sticas do dataset:**
   - Total de exemplos (treino/teste/total)
   - Distribui√ß√£o de classes (positivos/negativos)
   - Tamanho m√©dio dos textos (n√∫mero de palavras)

4. **Salva estat√≠sticas em CSV:**
   ```python
   # dataset_statistics.csv
   ```

5. **Exibe mensagens de confirma√ß√£o**

**Arquivos gerados:**
- `processed_train.csv` - 10.000 linhas (se sample_size=10000)
- `processed_test.csv` - 10.000 linhas
- `dataset_statistics.csv` - 3 linhas (treino, teste, total)

---

### `train(self, X_train, y_train)`

**Descri√ß√£o:** Treina o modelo de classifica√ß√£o usando os dados de treino.

**Par√¢metros:**
- `X_train`: Textos de treino (processados)
- `y_train`: Labels correspondentes (0 ou 1)

**Retorna:** Nenhum (atualiza `self.model` e `self.vectorizer`)

**O que faz:**

1. **Cria e treina o TF-IDF Vectorizer:**
   ```python
   self.vectorizer = TfidfVectorizer(
       max_features=5000,      # Top 5000 palavras mais importantes
       min_df=2,               # Palavra deve aparecer em pelo menos 2 documentos
       max_df=0.8,             # Ignora palavras em mais de 80% dos documentos
       ngram_range=(1, 2)      # Considera palavras individuais e pares
   )
   ```

   **TF-IDF (Term Frequency-Inverse Document Frequency):**
   - Converte texto em n√∫meros
   - Palavras mais raras e importantes recebem pesos maiores
   - Palavras muito comuns recebem pesos menores

   **ngram_range=(1,2) significa:**
   - Unigrams: "great", "movie"
   - Bigrams: "great movie", "bad acting"

2. **Transforma textos em vetores:**
   ```python
   X_train_tfidf = self.vectorizer.fit_transform(X_train)
   # Cada texto vira um vetor de 5000 n√∫meros
   ```

3. **Cria e treina o modelo escolhido:**
   
   **Se Logistic Regression:**
   ```python
   self.model = LogisticRegression(
       max_iter=1000,    # M√°ximo 1000 itera√ß√µes
       random_state=42,  # Reprodutibilidade
       n_jobs=-1         # Usa todos os CPUs dispon√≠veis
   )
   ```
   
   **Se Naive Bayes:**
   ```python
   self.model = MultinomialNB()
   ```

4. **Ajusta o modelo aos dados:**
   ```python
   self.model.fit(X_train_tfidf, y_train)
   # Aprende os padr√µes de palavras positivas/negativas
   ```

**Por que Logistic Regression √© padr√£o?**
- Melhor performance em textos
- Fornece probabilidades calibradas
- Permite ver quais palavras s√£o mais importantes

---

### `evaluate(self, X_test, y_test)`

**Descri√ß√£o:** Avalia o desempenho do modelo treinado usando dados de teste.

**Par√¢metros:**
- `X_test`: Textos de teste (processados)
- `y_test`: Labels verdadeiros

**Retorna:** Dictionary com:
```python
{
    'accuracy': 0.8680,              # Acur√°cia geral
    'predictions': array([1,0,1...]), # Predi√ß√µes do modelo
    'confusion_matrix': array([[...]])  # Matriz de confus√£o
}
```

**O que faz:**

1. **Transforma textos de teste em vetores:**
   ```python
   X_test_tfidf = self.vectorizer.transform(X_test)
   # Usa o mesmo vetorizador do treino
   ```

2. **Faz predi√ß√µes:**
   ```python
   y_pred = self.model.predict(X_test_tfidf)
   ```

3. **Calcula acur√°cia:**
   ```python
   accuracy = accuracy_score(y_test, y_pred)
   # Percentual de acertos
   ```

4. **Gera relat√≥rio de classifica√ß√£o:**
   - **Precision (Precis√£o):** De todas as predi√ß√µes positivas, quantas estavam corretas?
   - **Recall (Revoca√ß√£o):** De todos os casos positivos reais, quantos foram identificados?
   - **F1-Score:** M√©dia harm√¥nica entre Precision e Recall

5. **Exibe resultados formatados:**
   ```
   RESULTADOS DA AVALIA√á√ÉO
   Acur√°cia: 0.8680 (86.80%)
   
                 precision  recall  f1-score
   Negativo       0.87      0.86      0.87
   Positivo       0.86      0.87      0.87
   ```

6. **Cria matriz de confus√£o:**
   ```
   [[VP  FN]    VP = Verdadeiros Positivos
    [FP  VN]]    VN = Verdadeiros Negativos
                 FP = Falsos Positivos
                 FN = Falsos Negativos
   ```

---

### `predict_sentiment(self, text)`

**Descri√ß√£o:** Prediz o sentimento de um novo texto (review).

**Par√¢metros:**
- `text` (str): Texto/review a ser analisado

**Retorna:** Tupla com:
```python
(sentiment, confidence)
# sentiment: "POSITIVO" ou "NEGATIVO"
# confidence: 0-100 (percentual de confian√ßa)
```

**O que faz:**

1. **Verifica se modelo est√° treinado:**
   ```python
   if self.model is None or self.vectorizer is None:
       raise ValueError("Modelo n√£o treinado")
   ```

2. **Pr√©-processa o texto:**
   ```python
   processed = self.preprocess_text(text)
   ```

3. **Vetoriza o texto:**
   ```python
   vectorized = self.vectorizer.transform([processed])
   ```

4. **Faz predi√ß√£o:**
   ```python
   prediction = self.model.predict(vectorized)[0]  # 0 ou 1
   ```

5. **Calcula probabilidades:**
   ```python
   probability = self.model.predict_proba(vectorized)[0]
   # Retorna [prob_negativo, prob_positivo]
   ```

6. **Formata resultado:**
   ```python
   sentiment = "POSITIVO" if prediction == 1 else "NEGATIVO"
   confidence = probability[prediction] * 100
   ```

**Exemplo de uso:**
```python
text = "This movie was absolutely amazing!"
sentiment, confidence = classifier.predict_sentiment(text)
print(f"{sentiment} ({confidence:.2f}%)")
# Sa√≠da: POSITIVO (95.23%)
```

---

### `save_model(self, model_path=None, vectorizer_path=None)`

**Descri√ß√£o:** Salva o modelo treinado e o vetorizador em arquivos .pkl para uso futuro.

**Par√¢metros:**
- `model_path` (str, opcional): Caminho customizado para salvar o modelo
- `vectorizer_path` (str, opcional): Caminho customizado para salvar o vetorizador

**Retorna:** Nenhum

**O que faz:**

1. **Obt√©m diret√≥rio de modelos:**
   ```python
   models_dir = self._get_project_dirs()['models']
   models_dir.mkdir(exist_ok=True)
   ```

2. **Define caminhos padr√£o (se n√£o fornecidos):**
   ```python
   model_path = models_dir / 'sentiment_model.pkl'
   vectorizer_path = models_dir / 'tfidf_vectorizer.pkl'
   ```

3. **Serializa e salva o modelo:**
   ```python
   with open(model_path, 'wb') as f:
       pickle.dump(self.model, f)
   ```

4. **Serializa e salva o vetorizador:**
   ```python
   with open(vectorizer_path, 'wb') as f:
       pickle.dump(self.vectorizer, f)
   ```

5. **Exibe confirma√ß√£o**

**Por que salvar o modelo?**
- Evita re-treinar (economiza tempo)
- Permite usar o modelo em outros scripts
- √ötil para deploy em produ√ß√£o

**Formato .pkl:**
- Pickle = serializa√ß√£o Python
- Guarda objetos Python completos
- Pode ser carregado com `pickle.load()`

---

### `load_model(self, model_path=None, vectorizer_path=None)`

**Descri√ß√£o:** Carrega um modelo e vetorizador previamente salvos.

**Par√¢metros:**
- `model_path` (str, opcional): Caminho do modelo salvo
- `vectorizer_path` (str, opcional): Caminho do vetorizador salvo

**Retorna:** Nenhum (atualiza `self.model` e `self.vectorizer`)

**O que faz:**

1. **Obt√©m diret√≥rio de modelos:**
   ```python
   models_dir = self._get_project_dirs()['models']
   ```

2. **Define caminhos padr√£o (se n√£o fornecidos):**
   ```python
   model_path = models_dir / 'sentiment_model.pkl'
   vectorizer_path = models_dir / 'tfidf_vectorizer.pkl'
   ```

3. **Carrega o modelo:**
   ```python
   with open(model_path, 'rb') as f:
       self.model = pickle.load(f)
   ```

4. **Carrega o vetorizador:**
   ```python
   with open(vectorizer_path, 'rb') as f:
       self.vectorizer = pickle.load(f)
   ```

5. **Exibe confirma√ß√£o**

**Uso t√≠pico:**
```python
# Criar inst√¢ncia
classifier = SentimentClassifier()

# Carregar modelo salvo (sem treinar)
classifier.load_model()

# Usar imediatamente
sentiment, conf = classifier.predict_sentiment("Great movie!")
```

---

## Fun√ß√£o generate_visualizations

### `generate_visualizations(classifier, results, X_test, y_test)`

**Descri√ß√£o:** Gera uma visualiza√ß√£o completa com 6 gr√°ficos mostrando o desempenho do modelo.

**Par√¢metros:**
- `classifier`: Inst√¢ncia do SentimentClassifier treinado
- `results`: Dictionary retornado por `evaluate()` com m√©tricas
- `X_test`: Textos de teste
- `y_test`: Labels de teste verdadeiros

**Retorna:** Nenhum (salva imagem em `/visualizations/model_analysis.png`)

**O que faz:**

### 1. Setup Inicial
```python
# Obt√©m diret√≥rio e cria se n√£o existir
viz_dir = SentimentClassifier._get_project_dirs()['visualizations']
viz_dir.mkdir(exist_ok=True)

# Configura estilo dos gr√°ficos
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Cria figura com 6 subplots (2 linhas x 3 colunas)
fig = plt.figure(figsize=(16, 10))
```

### 2. Gr√°fico 1: Matriz de Confus√£o (Canto Superior Esquerdo)
```python
ax1 = plt.subplot(2, 3, 1)
```

**O que mostra:**
- Heatmap 2x2 com cores azuis
- Linha = Valor Real, Coluna = Valor Predito
- C√©lulas mostram quantidades:
  - [0,0] = Negativos classificados como Negativos ‚úì
  - [0,1] = Negativos classificados como Positivos ‚úó
  - [1,0] = Positivos classificados como Negativos ‚úó
  - [1,1] = Positivos classificados como Positivos ‚úì

**Interpreta√ß√£o:**
- Diagonal principal alta = bom modelo
- C√©lulas fora da diagonal = erros

### 3. Gr√°fico 2: M√©tricas por Classe (Centro Superior)
```python
ax2 = plt.subplot(2, 3, 2)
```

**O que mostra:**
- Gr√°fico de barras agrupadas
- 3 m√©tricas √ó 2 classes = 6 barras
- Vermelho (#ff6b6b) = Classe Negativa
- Azul-verde (#4ecdc4) = Classe Positiva
- Valores de 0 a 1 no eixo Y

**M√©tricas exibidas:**
- **Precision:** Acertos / (Acertos + Falsos Positivos)
- **Recall:** Acertos / (Acertos + Falsos Negativos)
- **F1-Score:** 2 √ó (Precision √ó Recall) / (Precision + Recall)

**Valores aparecem acima de cada barra**

### 4. Gr√°fico 3: Acur√°cia Geral (Canto Superior Direito)
```python
ax3 = plt.subplot(2, 3, 3)
```

**O que mostra:**
- N√∫mero gigante verde (#2ecc71) centralizado
- Mostra acur√°cia em percentual (ex: 86.80%)
- Texto "Acur√°cia Geral" abaixo
- Sem eixos (tipo "card")

**Por que destacar?**
- M√©trica mais importante
- F√°cil visualiza√ß√£o r√°pida

### 5. Gr√°fico 4: Top 15 Palavras Positivas (Canto Inferior Esquerdo)
```python
ax4 = plt.subplot(2, 3, 4)
```

**O que mostra:**
- Barras horizontais em tons de verde
- Palavras que mais indicam sentimento POSITIVO
- Eixo X = Peso do coeficiente do modelo
- Quanto maior o peso, mais positiva a palavra

**Exemplos t√≠picos:**
- "excellent", "great", "best"
- "amazing", "wonderful", "perfect"
- "loved", "favorite", "recommend"

**Como funciona:**
```python
coef = classifier.model.coef_[0]  # Pesos de todas as palavras
top_indices = np.argsort(coef)[-15:]  # 15 maiores pesos
```

### 6. Gr√°fico 5: Top 15 Palavras Negativas (Centro Inferior)
```python
ax5 = plt.subplot(2, 3, 5)
```

**O que mostra:**
- Barras horizontais em tons de vermelho
- Palavras que mais indicam sentimento NEGATIVO
- Eixo X = Peso do coeficiente (valores negativos)
- Quanto mais negativo o peso, mais negativa a palavra

**Exemplos t√≠picos:**
- "worst", "terrible", "awful"
- "boring", "waste", "disappointing"
- "bad", "poor", "horrible"

**Como funciona:**
```python
top_indices = np.argsort(coef)[:15]  # 15 menores pesos
```

### 7. Gr√°fico 6: Distribui√ß√£o de Predi√ß√µes (Canto Inferior Direito)
```python
ax6 = plt.subplot(2, 3, 6)
```

**O que mostra:**
- Gr√°fico de barras simples
- 2 barras: quantidade de predi√ß√µes Negativas e Positivas
- Cores: vermelho (negativo) e azul-verde (positivo)
- Valores aparecem no topo de cada barra

**Por que √© √∫til:**
- Verifica se modelo est√° balanceado
- Detecta vi√©s (ex: prediz tudo como positivo)
- Ideal: ~50/50 se dataset √© balanceado

### 8. Finaliza√ß√£o
```python
plt.tight_layout()  # Ajusta espa√ßamento autom√°tico

# Salva em alta resolu√ß√£o
output_path = viz_dir / 'model_analysis.png'
plt.savefig(str(output_path), dpi=300, bbox_inches='tight')

plt.close()  # Libera mem√≥ria
```

**Par√¢metros de salvamento:**
- `dpi=300` = Alta qualidade (300 pontos por polegada)
- `bbox_inches='tight'` = Remove espa√ßos em branco extras

---

## Fun√ß√£o main

### `main()`

**Descri√ß√£o:** Fun√ß√£o principal que orquestra todo o pipeline de treinamento, avalia√ß√£o e teste.

**Par√¢metros:** Nenhum

**Retorna:** Nenhum

**O que faz (fluxo completo):**

### 1. Exibe Header
```python
print("="*70)
print("CLASSIFICA√á√ÉO DE SENTIMENTOS EM AVALIA√á√ïES DE FILMES")
print("="*70)
```

### 2. Cria Inst√¢ncia do Classificador
```python
classifier = SentimentClassifier(
    model_type='logistic_regression',  # Pode alterar para 'naive_bayes'
    max_features=5000                   # Pode aumentar para 10000+
)
```

### 3. Carrega e Processa Dados
```python
X_train, y_train, X_test, y_test = classifier.load_data(sample_size=1000)
```

**Configura√ß√µes atuais:**
- `sample_size=1000` = Usa 1000 exemplos de treino e teste
- `save_processed=True` (padr√£o) = Salva CSVs em `/data/`

**Para dataset completo:**
```python
classifier.load_data(sample_size=None)  # 25.000 treino + 25.000 teste
```

### 4. Treina o Modelo
```python
classifier.train(X_train, y_train)
```

**Processos internos:**
- Cria vetorizador TF-IDF
- Transforma textos em n√∫meros
- Treina modelo de Machine Learning
- Aprende padr√µes de palavras positivas/negativas

### 5. Avalia Desempenho
```python
results = classifier.evaluate(X_test, y_test)
```

**Exibe no console:**
- Acur√°cia geral
- Precision, Recall, F1-Score por classe
- Relat√≥rio completo

### 6. Salva Modelo
```python
classifier.save_model()
```

**Arquivos criados:**
- `/models/sentiment_model.pkl` (~5 MB)
- `/models/tfidf_vectorizer.pkl` (~15 MB)

### 7. Gera Visualiza√ß√µes
```python
generate_visualizations(classifier, results, X_test, y_test)
```

**Arquivo criado:**
- `/visualizations/model_analysis.png` (imagem com 6 gr√°ficos)

### 8. Testa com Exemplos
```python
test_reviews = [
    "This movie was absolutely amazing! The acting was superb and the plot was engaging.",
    "Terrible film. Waste of time and money. I couldn't even finish watching it.",
    "It was okay, nothing special but not terrible either.",
    "Best movie I've seen in years! Highly recommended!",
    "Boring and predictable. The worst movie of the year."
]

for review in test_reviews:
    sentiment, confidence = classifier.predict_sentiment(review)
    print(f"Sentimento: {sentiment} (Confian√ßa: {confidence:.2f}%)")
```

**Sa√≠da esperada:**
```
Review 1: This movie was absolutely amazing!...
Sentimento: POSITIVO (Confian√ßa: 95.23%)
----------------------------------------------------------------------

Review 2: Terrible film. Waste of time and money...
Sentimento: NEGATIVO (Confian√ßa: 98.54%)
----------------------------------------------------------------------
...
```

### 9. Finaliza
```python
print("PROCESSO CONCLU√çDO COM SUCESSO!")
```

---

## üîß Configura√ß√µes e Customiza√ß√µes

### Como ajustar o tamanho do dataset?

No m√©todo `main()`, linha:
```python
X_train, y_train, X_test, y_test = classifier.load_data(sample_size=1000)
```

**Op√ß√µes:**
- `sample_size=1000` - R√°pido (1-2 min), ~78-82% acur√°cia
- `sample_size=5000` - M√©dio (3-5 min), ~84-86% acur√°cia
- `sample_size=10000` - Bom (5-8 min), ~86-88% acur√°cia
- `sample_size=None` - Completo (10-15 min), ~88-90% acur√°cia

### Como mudar o n√∫mero de features?

No construtor:
```python
classifier = SentimentClassifier(
    model_type='logistic_regression',
    max_features=10000  # Aumentar para capturar mais palavras
)
```

**Impacto:**
- Mais features = Modelo mais preciso (at√© certo ponto)
- Mais features = Mais lento e usa mais mem√≥ria
- Recomendado: 5000-15000 para este dataset

### Como trocar o algoritmo?

```python
# Op√ß√£o 1: Logistic Regression (padr√£o, recomendado)
classifier = SentimentClassifier(model_type='logistic_regression')

# Op√ß√£o 2: Naive Bayes (mais r√°pido, menos preciso)
classifier = SentimentClassifier(model_type='naive_bayes')
```

**Compara√ß√£o:**
| Algoritmo | Velocidade | Acur√°cia | Interpretabilidade |
|-----------|------------|----------|-------------------|
| Logistic Regression | M√©dia | Alta (86-88%) | Alta (pesos das palavras) |
| Naive Bayes | R√°pida | M√©dia (82-85%) | M√©dia |

---

## üìä M√©tricas de Avalia√ß√£o Explicadas

### Acur√°cia (Accuracy)
```
Acur√°cia = (Acertos) / (Total)
```
- Percentual geral de acertos
- **Problema:** Pode enganar se classes desbalanceadas

### Precision (Precis√£o)
```
Precision = VP / (VP + FP)
```
- De todas as predi√ß√µes POSITIVAS, quantas estavam corretas?
- **Alta precision:** Poucas classifica√ß√µes erradas como positivo

### Recall (Revoca√ß√£o)
```
Recall = VP / (VP + FN)
```
- De todos os casos POSITIVOS reais, quantos foram identificados?
- **Alto recall:** Pegou a maioria dos positivos

### F1-Score
```
F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
```
- M√©dia harm√¥nica entre Precision e Recall
- **Melhor m√©trica** quando classes desbalanceadas

### Matriz de Confus√£o

```
                 Predito
              Neg    Pos
Real  Neg  [  VP  |  FN  ]
      Pos  [  FP  |  VN  ]
```

- **VP (Verdadeiros Positivos):** Acertou o positivo ‚úì
- **VN (Verdadeiros Negativos):** Acertou o negativo ‚úì
- **FP (Falsos Positivos):** Erro - disse positivo mas era negativo ‚úó
- **FN (Falsos Negativos):** Erro - disse negativo mas era positivo ‚úó

---

## üéØ Fluxo Completo de Execu√ß√£o

```
1. Importar bibliotecas
   ‚Üì
2. Criar SentimentClassifier
   ‚Üì
3. Download recursos NLTK (autom√°tico)
   ‚Üì
4. Carregar dataset IMDb (Hugging Face)
   ‚Üì
5. Pr√©-processar textos
   ‚îú‚îÄ Limpar HTML
   ‚îú‚îÄ Lowercase
   ‚îú‚îÄ Tokenizar
   ‚îú‚îÄ Remover stopwords
   ‚îî‚îÄ Lematizar
   ‚Üì
6. Salvar dados processados (.csv)
   ‚Üì
7. Criar vetores TF-IDF
   ‚Üì
8. Treinar modelo (Logistic Regression)
   ‚Üì
9. Avaliar no conjunto de teste
   ‚Üì
10. Salvar modelo (.pkl)
    ‚Üì
11. Gerar visualiza√ß√µes (.png)
    ‚Üì
12. Testar com novos exemplos
    ‚Üì
13. Concluir ‚úì
```

---

## üöÄ Exemplos de Uso

### Uso B√°sico (Treinar e Salvar)
```python
# Criar e treinar
classifier = SentimentClassifier()
X_train, y_train, X_test, y_test = classifier.load_data(sample_size=5000)
classifier.train(X_train, y_train)
results = classifier.evaluate(X_test, y_test)
classifier.save_model()
```

### Carregar Modelo Existente
```python
# Criar inst√¢ncia
classifier = SentimentClassifier()

# Carregar modelo salvo (sem treinar)
classifier.load_model()

# Usar imediatamente
text = "This movie is incredible!"
sentiment, confidence = classifier.predict_sentiment(text)
print(f"{sentiment}: {confidence:.2f}%")
```

### Processar M√∫ltiplas Reviews
```python
reviews = [
    "Amazing cinematography and acting!",
    "Worst movie ever, don't waste your time",
    "It's okay, nothing special"
]

for review in reviews:
    sentiment, conf = classifier.predict_sentiment(review)
    print(f"{review[:30]}... ‚Üí {sentiment} ({conf:.1f}%)")
```

### An√°lise de Performance Customizada
```python
classifier = SentimentClassifier(max_features=10000)
X_train, y_train, X_test, y_test = classifier.load_data(sample_size=None)
classifier.train(X_train, y_train)

results = classifier.evaluate(X_test, y_test)
print(f"Acur√°cia: {results['accuracy']*100:.2f}%")
print(f"Total erros: {(results['predictions'] != y_test).sum()}")
```

---

## üìù Notas Importantes

### Performance Esperada
- **Sample 1000:** ~78-82% acur√°cia, 1-2 minutos
- **Sample 5000:** ~84-86% acur√°cia, 3-5 minutos
- **Sample 10000:** ~86-88% acur√°cia, 5-8 minutos
- **Dataset completo:** ~88-90% acur√°cia, 10-15 minutos

### Limita√ß√µes
1. **Apenas ingl√™s:** Modelo treinado em reviews em ingl√™s
2. **Bin√°rio:** Apenas positivo/negativo (sem neutro)
3. **Contexto:** N√£o entende sarcasmo ou ironia complexa
4. **Dom√≠nio:** Otimizado para reviews de filmes

### Poss√≠veis Melhorias
1. **Aumentar max_features** para 10000-15000
2. **Usar dataset completo** (sample_size=None)
3. **Adicionar bigramas** (j√° implementado com ngram_range=(1,2))
4. **Experimentar outros modelos** (SVM, Random Forest, Deep Learning)
5. **Ajustar hiperpar√¢metros** do TF-IDF

---

## üîç Troubleshooting

### Erro: "Modelo n√£o treinado"
**Solu√ß√£o:** Execute `train()` antes de `predict_sentiment()`

### Baixa acur√°cia (<75%)
**Poss√≠veis causas:**
- sample_size muito pequeno
- max_features muito baixo
- Dados de teste diferentes do treino

### Script muito lento
**Solu√ß√µes:**
- Reduzir sample_size
- Reduzir max_features
- Usar Naive Bayes (mais r√°pido)

### Erro ao salvar/carregar modelo
**Verificar:**
- Pasta `/models/` existe?
- Permiss√µes de escrita
- Espa√ßo em disco

---

**Documenta√ß√£o criada para:** Projeto de Classifica√ß√£o de Sentimentos  
**Vers√£o:** 1.0  
**Data:** 18 de Novembro de 2025
