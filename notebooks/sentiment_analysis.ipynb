{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a48497",
   "metadata": {},
   "source": [
    "## 1. Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Configurações\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e94ced",
   "metadata": {},
   "source": [
    "## 2. Download de Recursos NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download de recursos necessários do NLTK\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "print(\"✓ Recursos NLTK baixados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13433b92",
   "metadata": {},
   "source": [
    "## 3. Carregamento do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe1e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset IMDb\n",
    "print(\"Carregando dataset IMDb...\")\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "# Converter para DataFrame\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "print(f\"\\n✓ Dataset carregado com sucesso!\")\n",
    "print(f\"  - Tamanho do conjunto de treino: {len(train_df)}\")\n",
    "print(f\"  - Tamanho do conjunto de teste: {len(test_df)}\")\n",
    "print(f\"\\nPrimeiras linhas do dataset:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d2a99",
   "metadata": {},
   "source": [
    "## 4. Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56fa337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações básicas\n",
    "print(\"Informações do Dataset:\")\n",
    "print(train_df.info())\n",
    "print(\"\\nEstatísticas Descritivas:\")\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c71d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição das classes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gráfico de barras\n",
    "train_df['label'].value_counts().plot(kind='bar', ax=axes[0], color=['#ff6b6b', '#4ecdc4'])\n",
    "axes[0].set_title('Distribuição das Classes - Treino', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Sentimento (0=Negativo, 1=Positivo)', fontsize=12)\n",
    "axes[0].set_ylabel('Quantidade', fontsize=12)\n",
    "axes[0].set_xticklabels(['Negativo', 'Positivo'], rotation=0)\n",
    "\n",
    "# Gráfico de pizza\n",
    "train_df['label'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
    "                                       colors=['#ff6b6b', '#4ecdc4'], startangle=90)\n",
    "axes[1].set_title('Proporção das Classes', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "axes[1].legend(['Negativo', 'Positivo'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBalanceamento das classes:\")\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a53db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise do tamanho dos textos\n",
    "train_df['text_length'] = train_df['text'].apply(len)\n",
    "train_df['word_count'] = train_df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribuição do tamanho dos textos\n",
    "axes[0].hist(train_df['text_length'], bins=50, color='#4ecdc4', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Distribuição do Tamanho dos Textos (caracteres)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Número de Caracteres', fontsize=12)\n",
    "axes[0].set_ylabel('Frequência', fontsize=12)\n",
    "axes[0].axvline(train_df['text_length'].mean(), color='red', linestyle='--', label=f'Média: {train_df[\"text_length\"].mean():.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Distribuição do número de palavras\n",
    "axes[1].hist(train_df['word_count'], bins=50, color='#ff6b6b', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Distribuição do Número de Palavras', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Número de Palavras', fontsize=12)\n",
    "axes[1].set_ylabel('Frequência', fontsize=12)\n",
    "axes[1].axvline(train_df['word_count'].mean(), color='red', linestyle='--', label=f'Média: {train_df[\"word_count\"].mean():.0f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nEstatísticas do tamanho dos textos:\")\n",
    "print(f\"  - Média de caracteres: {train_df['text_length'].mean():.2f}\")\n",
    "print(f\"  - Média de palavras: {train_df['word_count'].mean():.2f}\")\n",
    "print(f\"  - Máximo de caracteres: {train_df['text_length'].max()}\")\n",
    "print(f\"  - Máximo de palavras: {train_df['word_count'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2688b",
   "metadata": {},
   "source": [
    "## 5. Pré-processamento de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404801db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Pré-processa o texto:\n",
    "    1. Remove HTML tags\n",
    "    2. Converte para minúsculas\n",
    "    3. Remove caracteres especiais\n",
    "    4. Remove stopwords\n",
    "    5. Aplica lematização\n",
    "    \"\"\"\n",
    "    # Decodificar entidades HTML\n",
    "    text = unescape(text)\n",
    "    \n",
    "    # Remover HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Converter para minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remover URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remover caracteres especiais e números (mantém apenas letras)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenização\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remover stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    \n",
    "    # Lematização\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Teste da função\n",
    "sample_text = train_df['text'].iloc[0][:200]\n",
    "print(\"Texto original:\")\n",
    "print(sample_text)\n",
    "print(\"\\nTexto processado:\")\n",
    "print(preprocess_text(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825805fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar pré-processamento (usando uma amostra para demonstração)\n",
    "# Para o dataset completo, isso pode levar alguns minutos\n",
    "\n",
    "# Usar uma amostra menor para demonstração (remova o .sample() para usar o dataset completo)\n",
    "SAMPLE_SIZE = 5000  # Use None para processar todo o dataset\n",
    "\n",
    "if SAMPLE_SIZE:\n",
    "    train_sample = train_df.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "    test_sample = test_df.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "    print(f\"\\nUsando amostra de {SAMPLE_SIZE} exemplos para treino e teste\")\n",
    "else:\n",
    "    train_sample = train_df\n",
    "    test_sample = test_df\n",
    "    print(f\"\\nUsando dataset completo\")\n",
    "\n",
    "print(\"\\nProcessando textos de treino...\")\n",
    "train_sample['processed_text'] = train_sample['text'].progress_apply(preprocess_text)\n",
    "\n",
    "print(\"Processando textos de teste...\")\n",
    "test_sample['processed_text'] = test_sample['text'].progress_apply(preprocess_text)\n",
    "\n",
    "print(\"\\n✓ Pré-processamento concluído!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133bcb9c",
   "metadata": {},
   "source": [
    "## 6. Vetorização com TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados\n",
    "X_train = train_sample['processed_text']\n",
    "y_train = train_sample['label']\n",
    "X_test = test_sample['processed_text']\n",
    "y_test = test_sample['label']\n",
    "\n",
    "# Criar vetorizador TF-IDF\n",
    "print(\"Criando vetores TF-IDF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limitar a 5000 features mais importantes\n",
    "    min_df=2,           # Palavra deve aparecer em pelo menos 2 documentos\n",
    "    max_df=0.8,         # Palavra não deve aparecer em mais de 80% dos documentos\n",
    "    ngram_range=(1, 2)  # Usar unigramas e bigramas\n",
    ")\n",
    "\n",
    "# Transformar textos em vetores\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\n✓ Vetorização concluída!\")\n",
    "print(f\"  - Shape do conjunto de treino: {X_train_tfidf.shape}\")\n",
    "print(f\"  - Shape do conjunto de teste: {X_test_tfidf.shape}\")\n",
    "print(f\"  - Número de features: {len(tfidf_vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2617f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar as palavras mais importantes\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"\\nExemplos de features (palavras e bigramas):\")\n",
    "print(feature_names[:20])\n",
    "print(\"...\")\n",
    "print(feature_names[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd33309f",
   "metadata": {},
   "source": [
    "## 7. Treinamento dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a956d8",
   "metadata": {},
   "source": [
    "### 7.1 Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Treinando Regressão Logística...\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Fazer predições\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Avaliar modelo\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"\\n✓ Regressão Logística treinada!\")\n",
    "print(f\"  Acurácia: {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17718979",
   "metadata": {},
   "source": [
    "### 7.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c08bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Treinando Naive Bayes...\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Fazer predições\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Avaliar modelo\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"\\n✓ Naive Bayes treinado!\")\n",
    "print(f\"  Acurácia: {nb_accuracy:.4f} ({nb_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfbcf0a",
   "metadata": {},
   "source": [
    "## 8. Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b10adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação de acurácia\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Modelo': ['Regressão Logística', 'Naive Bayes'],\n",
    "    'Acurácia': [lr_accuracy, nb_accuracy]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARAÇÃO DOS MODELOS\")\n",
    "print(\"=\"*50)\n",
    "print(models_comparison.to_string(index=False))\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Visualizar comparação\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models_comparison['Modelo'], models_comparison['Acurácia'], \n",
    "               color=['#4ecdc4', '#ff6b6b'], alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "plt.title('Comparação de Acurácia dos Modelos', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Acurácia', fontsize=12)\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.4f}\\n({height*100:.2f}%)',\n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatório de classificação para Regressão Logística\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REGRESSÃO LOGÍSTICA - Relatório Detalhado\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Negativo', 'Positivo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatório de classificação para Naive Bayes\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NAIVE BAYES - Relatório Detalhado\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred_nb, target_names=['Negativo', 'Positivo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db18a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrizes de confusão\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matriz de confusão - Regressão Logística\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0], \n",
    "            xticklabels=['Negativo', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "axes[0].set_title('Matriz de Confusão - Regressão Logística', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Valor Real', fontsize=12)\n",
    "axes[0].set_xlabel('Valor Predito', fontsize=12)\n",
    "\n",
    "# Matriz de confusão - Naive Bayes\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Reds', ax=axes[1],\n",
    "            xticklabels=['Negativo', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "axes[1].set_title('Matriz de Confusão - Naive Bayes', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Valor Real', fontsize=12)\n",
    "axes[1].set_xlabel('Valor Predito', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae4127",
   "metadata": {},
   "source": [
    "## 9. Análise de Features Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras mais importantes para cada classe (Regressão Logística)\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "coef = lr_model.coef_[0]\n",
    "\n",
    "# Top palavras positivas\n",
    "top_positive_indices = np.argsort(coef)[-20:]\n",
    "top_positive_words = feature_names[top_positive_indices]\n",
    "top_positive_scores = coef[top_positive_indices]\n",
    "\n",
    "# Top palavras negativas\n",
    "top_negative_indices = np.argsort(coef)[:20]\n",
    "top_negative_words = feature_names[top_negative_indices]\n",
    "top_negative_scores = coef[top_negative_indices]\n",
    "\n",
    "# Visualização\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Palavras positivas\n",
    "axes[0].barh(range(len(top_positive_words)), top_positive_scores, color='#4ecdc4', alpha=0.8)\n",
    "axes[0].set_yticks(range(len(top_positive_words)))\n",
    "axes[0].set_yticklabels(top_positive_words)\n",
    "axes[0].set_xlabel('Peso (Coeficiente)', fontsize=12)\n",
    "axes[0].set_title('Top 20 Palavras Associadas a Sentimento POSITIVO', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Palavras negativas\n",
    "axes[1].barh(range(len(top_negative_words)), top_negative_scores, color='#ff6b6b', alpha=0.8)\n",
    "axes[1].set_yticks(range(len(top_negative_words)))\n",
    "axes[1].set_yticklabels(top_negative_words)\n",
    "axes[1].set_xlabel('Peso (Coeficiente)', fontsize=12)\n",
    "axes[1].set_title('Top 20 Palavras Associadas a Sentimento NEGATIVO', fontsize=14, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 palavras POSITIVAS:\")\n",
    "for word, score in zip(top_positive_words[-10:], top_positive_scores[-10:]):\n",
    "    print(f\"  {word:20s}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTop 10 palavras NEGATIVAS:\")\n",
    "for word, score in zip(top_negative_words[:10], top_negative_scores[:10]):\n",
    "    print(f\"  {word:20s}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5501387",
   "metadata": {},
   "source": [
    "## 10. Teste com Novos Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model=lr_model):\n",
    "    \"\"\"\n",
    "    Prediz o sentimento de um texto\n",
    "    \"\"\"\n",
    "    # Pré-processar texto\n",
    "    processed = preprocess_text(text)\n",
    "    \n",
    "    # Vetorizar\n",
    "    vectorized = tfidf_vectorizer.transform([processed])\n",
    "    \n",
    "    # Predizer\n",
    "    prediction = model.predict(vectorized)[0]\n",
    "    probability = model.predict_proba(vectorized)[0]\n",
    "    \n",
    "    sentiment = \"POSITIVO\" if prediction == 1 else \"NEGATIVO\"\n",
    "    confidence = probability[prediction] * 100\n",
    "    \n",
    "    return sentiment, confidence\n",
    "\n",
    "# Exemplos de teste\n",
    "test_reviews = [\n",
    "    \"This movie was absolutely amazing! The acting was superb and the plot was engaging.\",\n",
    "    \"Terrible film. Waste of time and money. I couldn't even finish watching it.\",\n",
    "    \"It was okay, nothing special but not terrible either.\",\n",
    "    \"Best movie I've seen in years! Highly recommended!\",\n",
    "    \"Boring and predictable. The worst movie of the year.\"\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TESTE COM NOVOS TEXTOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    sentiment, confidence = predict_sentiment(review)\n",
    "    print(f\"\\nReview {i}: {review}\")\n",
    "    print(f\"Sentimento: {sentiment} (Confiança: {confidence:.2f}%)\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf923f0",
   "metadata": {},
   "source": [
    "## 11. Salvando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efaeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Criar diretório se não existir\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Salvar modelo\n",
    "with open('../models/sentiment_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "\n",
    "# Salvar vetorizador\n",
    "with open('../models/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "print(\"✓ Modelo e vetorizador salvos com sucesso!\")\n",
    "print(\"  - Modelo: models/sentiment_model.pkl\")\n",
    "print(\"  - Vetorizador: models/tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a231459",
   "metadata": {},
   "source": [
    "## 12. Conclusões\n",
    "\n",
    "### Resultados Obtidos:\n",
    "\n",
    "1. **Regressão Logística**: Apresentou excelente performance na classificação de sentimentos\n",
    "2. **Naive Bayes**: Modelo mais rápido, com boa acurácia\n",
    "\n",
    "### Principais Descobertas:\n",
    "\n",
    "- O dataset IMDb é bem balanceado, facilitando o treinamento\n",
    "- Palavras como \"excellent\", \"great\", \"best\" são fortes indicadores de sentimento positivo\n",
    "- Palavras como \"worst\", \"bad\", \"terrible\" são fortes indicadores de sentimento negativo\n",
    "- A vetorização TF-IDF capturou bem as características importantes do texto\n",
    "\n",
    "### Possíveis Melhorias:\n",
    "\n",
    "1. Usar modelos mais avançados (LSTM, BERT, Transformers)\n",
    "2. Aumentar o tamanho do dataset de treino\n",
    "3. Aplicar técnicas de data augmentation\n",
    "4. Fazer fine-tuning de hiperparâmetros\n",
    "5. Considerar análise de aspectos específicos (acting, plot, cinematography)\n",
    "\n",
    "### Aplicações Práticas:\n",
    "\n",
    "- Sistema de recomendação de filmes\n",
    "- Análise de feedback de clientes\n",
    "- Monitoramento de reputação online\n",
    "- Dashboard de análise de sentimentos em tempo real"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
